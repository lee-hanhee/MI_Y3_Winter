
\begin{summary}
    \begin{center}
        \begin{tabular}{lcccccc}
        \toprule
        \textbf{Alg.} & Halting & Sound & Complete & Optimal & Time & Space \\
        \midrule
        \multicolumn{7}{p{\linewidth}}{
        \begin{center}
            \textbf{Uninformed Search Algorithms}
        \end{center}} \\
        \midrule
        \textbf{BFS} & $d<\infty$, non-\texttt{NULL} & always & always & constant cst & $b^{l^{*}}$ & $b^{l^{*} + 1}$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the least-recently expanded open node first.
        \end{itemize}} \\
        \midrule
        \textbf{DFS} & $d<\infty$ & always & $d < \infty$ & never & $b^{d}$ & $bd$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the most-recently expanded open node first.
        \end{itemize}} \\
        \midrule
        \textbf{IDDFS} & always & always & always & constant cst & $b^{l^{*}}$ & $bl^{*}$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Same as DFS but with iterative deepening.
        \end{itemize}} \\
        \midrule
        \textbf{CFS} & $d<\infty$, non-\texttt{NULL} & yes & $\epsilon >0$ & $\epsilon >0$ & $b^{c^{*} / \epsilon}$ & $b^{c^{*}/\epsilon + 1}$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the cheapest open node first.
        \end{itemize}} \\
        \midrule
        \multicolumn{7}{p{\linewidth}}{
        \begin{center}
            \textbf{Informed Search Algorithms}
        \end{center}} \\
        \midrule
        \textbf{HFS} & $d<\infty$ & never & never & never & - & - \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the node with the smallest hur-value first.
        \end{itemize}} \\
        \midrule
        \textbf{A$^*$} & hur admissible, $\epsilon > 0$ & always & hur admissible, $\epsilon > 0$ & hur admissible, $\epsilon > 0$ & $O\left(b^{c^{*}/\epsilon}\right)$ & $O\left(b^{c^{*}/\epsilon + 1}\right)$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the node with the smallest ecst-value first.
        \end{itemize}} \\
        \midrule
        \textbf{IIA$^*$} & always & always & always & always & $b^{l^{*}}$ & $bl^{*} $ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Same as A$^*$ but with iterative inflating on ecst.
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}

\subsection{Setup}
\begin{definition} In a search problem, it is assumed that: 
    \begin{itemize}
        \item There is only one agent (us).
        \item For each state, $s \in S$, we have a discrete set of actions, $\mathcal{A}(s)$.
        \item The transition resulting from a move, $(s, a)$, is deterministic; the resulting state is $tr(s, a)$.
        \item $cst(s, a, tr(s, a))$ is our cost for the transition, $(s, a, tr(s, a))$.
        \item We want to realize a path that minimizes our cost.
    \end{itemize}
    
    A search problem may have no solutions, in which case, we define the solution as \texttt{NULL}.
\end{definition}

\subsection{Search Graphs}
\begin{definition}
    In a search graph (a graph representing a search problem):
    \begin{itemize}
        \item $S$ is defined by the vertices.
        \item $\mathcal{G}$ is a subset of the vertices.
        \item $s^{(0)}$ is some vertex.
        \item $tr(\cdot, \cdot)$ and $\mathcal{T}$ are defined by the edges.
        \item $cst(\cdot, \cdot, \cdot)$ is defined by the edge weights.
    \end{itemize}
\end{definition}

\subsection{Path Trees}
\begin{definition}
    A search algorithm explores a tree of possible paths. 
    \begin{itemize}
        \item In such a tree, each node represents the path from the root to itself.
        \begin{itemize}
            \item The node may also include other info (such as the path's origiin, cost, etc).
        \end{itemize}
    \end{itemize}
\end{definition}

\subsection{Search Algorithms}
\begin{definition}
    All search algorithms follow the template below:

\begin{lstlisting}
$\mathcal{O} \gets \{(\langle \rangle, 0)\}$ (*\hfill $\triangleright$ initialize a set of open nodes*) 
SEARCH($\mathcal{O}$)
\end{lstlisting}
\begin{itemize}
    \item $\langle \rangle$ is the empty path, and $0$ is the cost of the empty path.
\end{itemize}

\begin{lstlisting}
procedure SEARCH($\mathcal{O}$)
    if $\mathcal{O} = \emptyset$ then
        return NULL  (*\hfill $\triangleright$ the search algorithm failed to find a path to a goal*)
    $n \gets \textsc{Remove}(\mathcal{O})$ (*\hfill $\triangleright$ "explore" a node $n$*)
    if $\textsc{dst}(n) \in \mathcal{G}$ then
        return $n$ (*\hfill $\triangleright$ the search algorithm found a path to a goal*)
    for $n' \in \textsc{chl}(n)$ do
        $\mathcal{O} \gets \mathcal{O} \cup \{n'\}$ (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
    SEARCH($\mathcal{O}$)
\end{lstlisting}
\begin{itemize}
    \item Explore: Remove a node from the open set.
    \item Exapnd: Generate the children of the node.
    \item Export: Add the children to the open set.
\end{itemize}

\end{definition}

\begin{warning}
    The key difference is in the order that \textsc{Remove}($\cdot$) removes nodes.
\end{warning}

\subsubsection{Characteristics of a Search Algorithm}
\begin{definition}
    We want to choose \texttt{REMOVE(Â·)} so that the algorithm exhibits the following characteristics:

    \begin{center}
        \begin{tabular}{|p{3cm}|p{9cm}|}
        \hline
        \textbf{Characteristic} & \textbf{Description} \\ \hline
        Halting & Terminates after finitely many nodes explored \\ \hline
        Sound & Returned (possibly NULL) solution is correct \\ \hline
        Complete & Halting and sound when a non-NULL solution exists \\ \hline
        Optimal & Returns an optimal solution when multiple exist \\ \hline
        Time Efficient & Minimizes the nodes \textbf{explored}/expanded/exported \\ \hline
        Space Efficient & Minimizes the nodes simultaneously open \\ \hline
        \end{tabular}
    \end{center}
    \vspace{1em}   
    \begin{itemize}
        \item Will be using explored for time efficiency.
    \end{itemize} 
    \vspace{1em}

    The characteristics of the algorithm also depend on several properties of the path tree over which it searches. These properties include:
    \begin{itemize}
        \item Branching factor: $b$ ($b < \infty$), the maximum number of children a node can have.
        \item Depth: $d$, the length of the longest path.
        \item Length of the shortest solution: $l^*$
        \item Cost of the cheapest solution: $c^*$
        \item Cost of the cheapest edge: $\epsilon$ 
    \end{itemize}

    We want to choose \texttt{REMOVE($\cdot$)} so that the algorithm exhibits the aforementioned characteristics for as many path trees as possible.

\end{definition}

\subsection{Modifications to Search Algorithms}
\subsubsection{Depth-Limiting}
\begin{definition}
    Depth limit of $d_{\text{max}}$ to any search algorithm by modifying \texttt{SEARCH($\cdot$)} as follows:
\begin{lstlisting}
procedure SEARCHDL($\mathcal{O}$, $d_{\text{max}}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL (*\hfill $\triangleright$ the search algorithm failed to find a path to a goal*)
    $n \leftarrow \text{REMOVE}(\mathcal{O})$ (*\hfill $\triangleright$ "explore" a node, $n$*)
    if dst($n$) $\in \mathcal{G}$ then
        return $n$ (*\hfill $\triangleright$ the search algorithm found a path to a goal*)
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if len($n'$) $\leq d_{\text{max}}$ then (*\hfill $\triangleright$ unless the child is too long*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCHDL($\mathcal{O}$, $d_{\text{max}}$)
\end{lstlisting}

\end{definition}

\subsubsection{Iterative Deepening}
\begin{definition}
    Iteratively increase the depth-limit, $d_{\max}$, to any search algorithm w/ depth-limiting, by placing \texttt{SEARCHDL($\cdot$)} in a wrapper, \texttt{SEARCHID($\cdot$)}:
\begin{lstlisting}
procedure SEARCHID():
    $n \leftarrow \text{NULL}$
    $d_{\text{max}} \leftarrow 0$
    (*$\triangleright$ while a solution has not been found, reset the open set, run the search algorithm, then increase the depth-limit*)
    while $n = \text{NULL}$ do
        $\mathcal{O} \leftarrow \{(\langle \rangle, 0)\}$
        $n \leftarrow \text{SEARCHDL}(\mathcal{O}, d_{\text{max}})$
        $d_{\text{max}} \leftarrow d_{\text{max}} + 1$
    return $n$
\end{lstlisting}
    
\end{definition}

\begin{warning}
    Increasing $d_{\text{max}}$ can be done in different ways.
\end{warning}

\subsubsection{Cost-Limiting}
\begin{definition}
    Cost limit of $c_{\text{max}}$ to any search algorithm by modifying \texttt{SEARCH($\cdot$)} as follows:

\begin{lstlisting}
procedure SEARCHCL($\mathcal{O}$, $c_{\text{max}}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL (*\hfill $\triangleright$ the search algorithm failed to find a path to a goal*)
    $n \leftarrow \text{REMOVE}(\mathcal{O})$ (*\hfill $\triangleright$ "explore" a node, $n$*)
    if dst($n$) $\in \mathcal{G}$ then
        return $n$ (*\hfill $\triangleright$ the search algorithm found a path to a goal*)
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if cst($n'$) $\leq c_{\text{max}}$ then (*\hfill $\triangleright$ unless the child is too expensive*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCHCL($\mathcal{O}$, $c_{\text{max}}$)
\end{lstlisting}

\end{definition}

\subsubsection{Iterative-Inflating}
\begin{definition}
    Iteratively increase the cost limit, $c_{\text{max}}$, to any search algorithm with cost-limiting, by placing \texttt{SEARCHCL($\cdot$)} in a wrapper, \texttt{SEARCHII($\cdot$)}:

\begin{lstlisting}
procedure SEARCHII():
    $n \leftarrow \text{NULL}$
    $c_{\text{max}} \leftarrow 0$
    (*$\triangleright$ while a solution has not been found, reset the open set, run the search algorithm, then increase the cost-limit*)
    while $n = \text{NULL}$ do
        $\mathcal{O} \leftarrow \{(\langle \rangle, 0)\}$
        $n \leftarrow \text{SEARCHCL}(\mathcal{O}, c_{\text{max}})$
        $c_{\text{max}} \leftarrow c_{\text{max}} + \epsilon$
    return $n$
\end{lstlisting}

\end{definition}

\begin{warning}
    Increasing $c_{\text{max}}$ can be done in different ways.
\end{warning}

\subsubsection{Intra-Path Cycle Checking}
\begin{definition}
    Do not expand a path if it is cyclic. Modify \texttt{SEARCH($\cdot$)} as follows:

\begin{lstlisting}
procedure SEARCH($\mathcal{O}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL
    $n \leftarrow \text{REMOVE}(\mathcal{O})$
    if dst($n$) $\in \mathcal{G}$ then
        return $n$
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if not CYCLIC($n'$) then (*\hfill $\triangleright$ unless the child is cyclic*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCH($\mathcal{O}$)
\end{lstlisting}
\begin{itemize}
    \item Optimately of an algorithm is preserved provided $\epsilon>0$.
\end{itemize}

\end{definition}

\subsubsection{Inter-Path Cycle Checking}
\begin{definition}
    We modify \texttt{SEARCH($\cdot$)} as follows:

\begin{lstlisting}
procedure SEARCH($\mathcal{O}$, $\mathcal{C}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL
    $n \leftarrow \text{REMOVE}(\mathcal{O})$
    $\mathcal{C} \leftarrow \mathcal{C} \cup \{n\}$ (*\hfill $\triangleright$ add $n$ to the closed set*)
    if dst($n$) $\in \mathcal{G}$ then
        return $n$
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if $n' \notin \mathcal{C}$ then (*\hfill $\triangleright$ unless the child's destination is closed*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCH($\mathcal{O}$, $\mathcal{C}$)
\end{lstlisting}

and then call the algorithm as follows:

\begin{lstlisting}[mathescape=true, escapeinside={(*}{*)}, numbers=left, frame=single]
$\mathcal{O} \leftarrow \{(\langle \rangle, 0)\}$
$\mathcal{C} \leftarrow \emptyset$ (*\hfill $\triangleright$ initialize a set of closed vertices*)
SEARCH($\mathcal{O}$, $\mathcal{C}$)
\end{lstlisting}

\end{definition}

\subsection{Informed Search Algorithms}
\subsubsection{Estimated Cost}
\begin{definition}
    $\text{ecst}(\cdot)$, to estimate the total cost to a goal given a path, $p$, based on the following:
    \begin{itemize}
        \item Cost of path $p$: $\text{cst}(p)$
        \item Estimate of the extra cost needed to get to a goal from $\text{dst}(p)$: $\text{hur} : S \to \mathbb{R}_+$
        \begin{itemize}
            \item $\text{hur}(s)$ estimates the cost to get to $\mathcal{G}$ from $s$ and $\text{hur}(p)$ means $\text{hur}(\text{dst}(p))$.
        \end{itemize}
    \end{itemize}
\end{definition}

\begin{example}
    Some common choices for $\text{ecst}(\cdot)$ include:
    \begin{enumerate}
        \item $\text{ecst}(p) = \text{hur}(p)$; called nearest-first search (NFS)
        \item $\text{ecst}(p) = \text{cst}(p) + \text{hur}(p)$; called A$^*$ (A-star)
    \end{enumerate}
\end{example}

\subsection{Characteristics of an Informed Search Algorithm}
\begin{definition}
    \begin{enumerate}
        \item Heuristic: $\text{hur}(\cdot)$
        \item Cost estimation: $\text{ecst}(\cdot)$
    \end{enumerate}
\end{definition}

\subsubsection{Heuristics}

\subsubsection{Designing Heuristics via Problem Relaxation}

\subsubsection{Combining Heuristics}

\subsection{Anytime Search Algorithms}

\subsection{Formulating a Search Problem}
\newpage

\subsection{Canonical Examples}
\begin{process} \textbf{How to setup a search problem?}
    \begin{enumerate}
        \item Givne a search graph, we need to define the following:
        \begin{itemize}
            \item $\mathcal{S}$: set of vertices
            \item $\mathcal{G}$: goal states (subset of $\mathcal{S}$)
            \item $s^{(0)}$: initial state
            \item $\mathcal{T}$: set of edges (defined by $\text{tr}(\cdot, \cdot)$)
            \begin{itemize}
                \item $\text{tr}(\cdot, \cdot)$: transition function
            \end{itemize}
            \item $\text{cst}(\cdot, \cdot, \cdot)$: cost function (defined by edge weights)
        \end{itemize}
    \end{enumerate}
\end{process}

\begin{example}
    \customFigure[0.5]{../Images/L2_0.png}{}
    \customFigure[0.5]{../Images/L2_1.png}{}
\end{example}
\newpage

\begin{example}
    \customFigure[0.5]{../Images/L2_9.png}{}
    \customFigure[0.5]{../Images/L2_10.png}{}
    \begin{itemize}
        \item $\mathcal{S} = \{0,\ldots,4 \}^2$
        \item $\mathcal{G} = \left\{ \begin{bmatrix}
            1 \\
            4
        \end{bmatrix} \right\}$
        \item $s^{(0)} = \begin{bmatrix}
            1 \\
            0
        \end{bmatrix}$
    \end{itemize}
\end{example}
\newpage


\begin{process} \textbf{How to setup a path tree?}
    \begin{enumerate}
        \item Start at $s^{(0)}$
        \item Choose a path until you reach a goal state.
        \item Repeat until you have found all paths (probably infinite).
    \end{enumerate}
\end{process}

\begin{example}
    \customFigure[0.5]{../Images/L2_2.png}{}
    \customFigure[0.5]{../Images/L2_3.png}{}
\end{example}

\newpage

\begin{process} \textbf{When to use each algorithm?}
    \begin{enumerate}
        \item Find properties needed for the problem and match them to the characteristics of the algorithm.
        \item Choose the algorithm that best matches the properties.
        \begin{itemize}
            \item \textbf{BFS:} 
            \item \textbf{DFS:} 
            \item \textbf{IDDFS:} 
            \item \textbf{CFS:}
            \item \textbf{A*:} 
        \end{itemize}
    \end{enumerate}
\end{process}

\begin{example}
    
\end{example}
\newpage

\begin{example}
    \customFigure[0.5]{../Images/LR_0.png}{}
\end{example}

\begin{process} \textbf{BFS}
    \begin{enumerate}
        \item Start at $s_0$ 
        \item Expand all neighboring nodes of the current node and add them to the open set (queue).
        \item Remove the current node from the open set and mark it as visited.
        \item Repeat steps 2 and 3 until the goal state is reached or the open set is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{BFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A\}$ \\
        $A$ & $\{B, C, D\}$ \\
        $AB$ & $\{C, D, E\}$ \\
        $ABC$ & $\{D, E\}$ \\
        $ABCD$ & $\{E\}$ \\
        $ABCDE$ & $\{\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{process} \textbf{DFS}
    \begin{enumerate}
        \item Start at $s_0$ (initial state).
        \item Push the initial node onto the stack.
        \item Pop a node from the stack and expand it.
        \item Push all unvisited children of the current node onto the stack.
        \item Repeat steps 3 and 4 until the goal state is reached or the stack is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{DFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A\}$ \\
        $A$ & $\{B,C,D\}$ \\
        $AD$ & $\{B,C,E\}$ \\
        $ADE$ & $\{C, B\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}


\begin{process} \textbf{IDDFS}
    \begin{enumerate}
        \item Start with a depth limit of 0.
        \item Perform Depth-First Search (DFS) up to the current depth limit.
        \item If the goal state is not reached and there are unexplored nodes, increment the depth limit and repeat step 2.
        \item Continue until the goal state is found or all nodes are explored.
    \end{enumerate}
\end{process}

\begin{example} \textbf{IDDFS}
    \begin{center}
        \begin{tabular}{lll}
        \toprule
        \textbf{Depth} & \textbf{Path} & \textbf{Open Set} \\
        \midrule
        0 & & $\{A\}$ \\
        0 & A & $\{\}$ \\
        \midrule
        1 & $A$ & $\{B, C, D\}$ \\
        1 & $AB$ & $\{C, D\}$ \\
        1 & $AC$ & $\{D\}$ \\
        1 & $AD$ & $\{\}$ \\
        \midrule
        2 & $AD$ & $\{E\}$ \\
        2 & $ADE$ & $\{\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{process} \textbf{CFS}
    \begin{enumerate}
        \item Start at $s_0$ (initial state).
        \item Initialize the open set (priority queue) with the initial state and its cost.
        \item Remove the node with the lowest cost from the open set.
        \item Expand the node and add all unvisited neighbors to the open set with their cumulative costs.
        \item Repeat steps 3 and 4 until the goal state is reached or the open set is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{CFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A \mid 0\}$ \\
        $A$ & $\{AB \mid 2, \; AC \mid 4, \; AD \mid 6\}$ \\
        $AB$ & $\{AC \mid 4, \; AD \mid 6, \; ABC \mid 3\}$ \\
        $ABC$ & $\{AC \mid 4, \; AD \mid 6, \; ABCE \mid 5, \; ABCD \mid 6\}$ \\
        $ABCE$ & $\{AC \mid 4, \; AD \mid 6, \; ABCD \mid 6\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{process} \textbf{HFS}
    \begin{enumerate}
        \item Start at $s_0$ (initial state).
        \item Initialize the open set with the initial state and its heuristic value.
        \item Remove the node with the lowest heuristic value from the open set.
        \item Expand the node and add all unvisited neighbors to the open set with their heuristic values.
        \item Repeat steps 3 and 4 until the goal state is reached or the open set is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{HFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A \mid 3\}$ \\
        $A$ & $\{AB \mid 2, \; AC \mid 1, \; AD \mid 1\}$ \\
        $AC$ & $\{AB \mid 2, \; AD \mid 1, \; ACE \mid 0\}$ \\
        $ACE$ & $\{AB \mid 2, \; AD \mid 1\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}


\begin{process} \textbf{A$^*$}
    \begin{enumerate}
        \item Start at $s_0$ 
        \item Choose path in open set that gives lowest $\text{esct}(p) = \text{cst}(p) + \text{hur}(p)$.
        \item Expand and export children onto open set.
        \item Repeat until goal state is reached.
    \end{enumerate}
\end{process}

\begin{example} \textbf{A$^*$}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A \mid 3 \}$ \\
        $A$ & $\{AB \mid 2 + 2, \; AC \mid 4 + 1, \; AD \mid 6 + 1\}$ \\
        $AB$ & $\{AC \mid 5, \; AD \mid 7, \; ABC \mid 3 + 1, \; \cancel{ABA} \quad \text{intra} \}$ \\
        $ABC$ & $\{AC \mid 5, AD \mid 7, \; ABCD \mid 6 + 1, \; ABCE \mid 5 + 0 \}$ \\
        $AC$ & $\{AD \mid 7, \; ABCD \mid 7, \; ABCE \mid 5, \; ACD \mid 7 + 1, \; ACE \mid 6 + 0 \}$ \\
        $ABCE$ & $\{AD \mid 7, \; ABCD \mid 7, \; ACD \mid 8, \; ACE \mid 6 \}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

% \multicolumn{2}{p{\linewidth}}{
%     \begin{itemize}
%         \item See the ELF header of a file.
%     \end{itemize}} \\



\begin{example} \textbf{IIA*}
    
\end{example}

\begin{example} \textbf{WA*}
    
\end{example}
\newpage

\begin{process} \textbf{How to Figure Out Soln. w/o Performing Search Algorithm?}
    \begin{enumerate}
        \item 
    \end{enumerate}
\end{process}

\begin{example} 
    
\end{example}
\newpage

\begin{process} \textbf{How to Prove Consistent/Admissible Given a Search Graph?}
   
    \textbf{Admissible:}
    \begin{enumerate}
        \item Given $\text{hur}(s)$ and search graph with $\text{cst}(s,a,\text{tr}(s,a))$ or $\text{rwd}(s,a,\text{tr}(s,a))$. If consistent, then it is admissible.
        \item Check $\forall s \in \mathcal{G}$, $\text{hur}(s) = 0$. If not, then it is not admissible.
        \item For each $s \in \mathcal{S}$, calculate $\text{hur}^*(s)$ (i.e. actual cost of optimal soln.) using the search graph.
        \begin{enumerate}
            \item Start at $s$ and choose path that gives the lowest cost or highest reward to $s \in \mathcal{G}$. 
        \end{enumerate}
        \item Check if $\text{hur}(s) \leq \text{hur}^*(s) \; \forall s \in \mathcal{S}$. If not, then it is not admissible.
        \item Repeat $\forall s \in \mathcal{S}$. 
        \item If all are true, then it is admissible.
    \end{enumerate}
    \vspace{1em}

    \textbf{Consistent:}
    \begin{enumerate}
        \item Given $\text{hur}(s)$ and search graph with $\text{cst}(s,a,\text{tr}(s,a))$ or $\text{rwd}(s,a,\text{tr}(s,a))$. 
        \item Check $\forall s \in \mathcal{G}$, $\text{hur}(s) = 0$. If not, then it is not consistent.
        \item For each $s \in \mathcal{S}$, calculate $\text{hur}(s) - \text{hur}(\text{tr}(s, a))$.
        \begin{enumerate}
            \item check if it is $\leq \text{cst}(s,a,\text{tr}(s,a))$ or $\geq \text{rwd}(s,a,\text{tr}(s,a))$. If not, then it is not consistent.
            \item Repeat $\forall a \in \mathcal{A}(s)$
        \end{enumerate}
        \item Repeat $\forall s \in \mathcal{S}$.
        \item If all are true, then it is consistent.
    \end{enumerate}
\end{process}

\begin{warning}
    Be careful of bidirectional edges bc for consistency you need compute the cost of the heuristic edge in both directions.
\end{warning}

\begin{example}
    \customFigure[0.5]{../Images/L2_8.png}{Jungle ($s^{(0)}$), Desert, Swamp, Mountain, Plains (Goal)}

    \textbf{Admissible:}
    \begin{enumerate}
        \item \textbf{$s=$Plains:} $\text{hur}(\text{Plains}) = 0$ 
        \item \textbf{$s=$Jungle:} $\text{hur}(\text{Jungle}) = 3 \leq \text{hur}^*(\text{Jungle}) = 2 + 1 + 2 = 5$
        \item \textbf{$s=$Desert:} $\text{hur}(\text{Desert}) = 2 \leq \text{hur}^*(\text{Desert}) = 1 + 2$
        \item \textbf{$s=$Swamp:} $\text{hur}(\text{Swamp}) = 1 \leq \text{hur}^*(\text{Swamp}) = 2$
        \item \textbf{$s=$Mountain:} $\text{hur}(\text{Mountain}) = 1 \leq \text{hur}^*(\text{Mountain}) = 1$
        \item Therefore, it is admissible.
    \end{enumerate}
    \vspace{1em}

    \textbf{Consistent:}
    \begin{enumerate}
        \item \textbf{$s=$Plains:} $\text{hur}(\text{Plains}) = 0$
        \item \textbf{$s=$Jungle:}
        \begin{enumerate}
            \item $\text{hur}(\text{Jungle}) - \text{hur}(\text{Desert}) = 3 - 2 = 1 \leq \text{cst}(\text{Jungle}, \cdot, \text{Desert}) = 2$
            \item $\text{hur}(\text{Jungle}) - \text{hur}(\text{Swamp}) = 3 - 1 = 2 \leq \text{cst}(\text{Jungle}, \cdot, \text{Swamp}) = 4$
            \item $\text{hur}(\text{Jungle}) - \text{hur}(\text{Mountain}) = 3 - 1 = 2 \leq \text{cst}(\text{Jungle}, \cdot, \text{Mountain}) = 6$
        \end{enumerate}
        \item \textbf{$s=$Desert:} 
        \begin{enumerate}
            \item $\text{hur}(\text{Desert}) - \text{hur}(\text{Jungle}) = 2 - 3 = -1 \leq \text{cst}(\text{Desert}, \cdot, \text{Jungle}) = 2$
            \item $\text{hur}(\text{Desert}) - \text{hur}(\text{Swamp}) = 2 - 1 = 1 \leq \text{cst}(\text{Desert}, \cdot, \text{Swamp}) = 1$
        \end{enumerate}
        \item \textbf{$s=$Swamp:}
        \begin{enumerate}
             \item $\text{hur}(\text{Swamp}) - \text{hur}(\text{Mountain}) = 1 - 1 = 0 \leq \text{cst}(\text{Swamp}, \cdot, \text{Mountain}) = 3$
            \item $\text{hur}(\text{Swamp}) - \text{hur}(\text{Plains}) = 1 - 0 = 1 \leq \text{cst}(\text{Swamp}, \cdot, \text{Plains}) = 2$
        \end{enumerate}
        \item \textbf{$s=$Mountain:} 
        \begin{enumerate}
            \item $\text{hur}(\text{Mountain}) - \text{hur}(\text{Jungle}) = 1 - 3 = -2 \leq \text{cst}(\text{Mountain}, \cdot, \text{Desert}) = 6$
            \item $\text{hur}(\text{Mountain}) - \text{hur}(\text{Plains}) = 1 - 0 = 1 \leq \text{cst}(\text{Mountain}, \cdot, \text{Plains}) = 1$
        \end{enumerate}
        \item Therefore, it is consistent.
    \end{enumerate}
\end{example}
\newpage

\begin{process} \textbf{How to Design Heuristic via Problem Relaxation?}
    \begin{enumerate}
        \item Make an assumption to simplify the problem as a relaxed problem. 
        \item Find the cost of the optimal solution of the relaxed problem, $\text{cst}_{\text{rel}}(s)$.
        \item HOW TO FIND THE COST OF THE OPTIMAL SOLUTION?
    \end{enumerate}
\end{process}

\begin{example}
    \customFigure[0.5]{../Images/L2_11.png}{}
\end{example}








