\begin{summary}
    \begin{center}
        \begin{tabular}{lcccccc}
        \toprule
        \textbf{Alg.} & Halting & Sound & Complete & Optimal & Time & Space \\
        \midrule
        \multicolumn{7}{p{\linewidth}}{
            Choose \texttt{REMOVE(Â·)} so algo. exhibits the characteristics:
            \begin{itemize}
                \item \textbf{Halting:} Terminates after finitely many nodes explored $\mid$ \textbf{Sound:} Returned (possibly NULL) soln. is correct 
                \item \textbf{Complete:} Halting \& sound when a non-NULL soln. exists $\mid$ \textbf{Opt.:} Returns an opt. soln. when mult. exist 
                \item \textbf{Time:} Minimizes nodes \textbf{explored}/expanded/exported $\mid$ \textbf{Space:} Minimizes nodes simultaneously open
            \end{itemize}} \\
        \midrule
        \multicolumn{7}{p{\linewidth}}{
            Choose \texttt{REMOVE($\cdot$)} so algo. exhibits the characteristics for as many path trees as possible. 
            \begin{itemize}
                \item $b$ ($b < \infty$): Branching factor (the maximum number of children a node can have)
                \item $d$: Depth (the length of the longest path), $l^*$: Length of the shortest solution
                \item $c^*$: Cost of the cheapest solution, $\epsilon$: Cost of the cheapest edge
            \end{itemize}
        } \\
        \midrule
        \multicolumn{7}{p{\linewidth}}{
        \begin{center}
            \textbf{Uninformed Search Algorithms}
        \end{center}} \\
        \midrule
        \textbf{BFS} & $d<\infty$, non-\texttt{NULL} & always & always & constant cst & $b^{l^{*}}$ & $b^{l^{*} + 1}$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the least-recently expanded open node first.
        \end{itemize}} \\
        \midrule
        \textbf{DFS} & $d<\infty$ & always & $d < \infty$ & never & $b^{d}$ & $bd$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the most-recently expanded open node first.
        \end{itemize}} \\
        \midrule
        \textbf{IDDFS} & always & always & always & constant cst & $b^{l^{*}}$ & $bl^{*}$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Same as DFS but with iterative deepening.
        \end{itemize}} \\
        \midrule
        \textbf{CFS} & $d<\infty$, non-\texttt{NULL} & yes & $\epsilon >0$ & $\epsilon >0$ & $b^{c^{*} / \epsilon}$ & $b^{c^{*}/\epsilon + 1}$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the cheapest open node first.
        \end{itemize}} \\
        \midrule
        \multicolumn{7}{p{\linewidth}}{
        \begin{center}
            \textbf{Informed Search Algorithms}
        \end{center}} \\
        \midrule
        \textbf{HFS} & $d<\infty$ & never & never & never & - & - \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the node with the smallest hur-value first, $\text{ecst}(p) = \text{hur}(p)$
        \end{itemize}} \\
        \midrule
        \textbf{A$^*$} & hur admissible, $\epsilon > 0$ & always & hur admissible, $\epsilon > 0$ & hur admissible, $\epsilon > 0$ & $O\left(b^{c^{*}/\epsilon}\right)$ & $O\left(b^{c^{*}/\epsilon + 1}\right)$ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Explores the node with the smallest ecst-value first, $\text{ecst}(p) = \text{cst}(p) + \text{hur}(p)$
        \end{itemize}} \\
        \midrule
        \textbf{IIA$^*$} & always & always & always & always & $b^{l^{*}}$ & $bl^{*} $ \\
        \multicolumn{7}{p{\linewidth}}{
        \begin{itemize}
            \item Same as A$^*$ but with iterative inflating on ecst.
        \end{itemize}} \\
        \midrule
        \textbf{WA$^*$} & - & - & - & - & - & - \\
        \multicolumn{7}{p{\linewidth}}{
            \begin{itemize}
                \item Same as A$^*$ but $\text{ecst}(s) = \text{wcst}(s) + (1-w)\text{hur}(s)$ w/ $w \in [0,1]$
                \item $w=0$: HFS, $w=0.5$: A$^*$, $w=1$: CFS, iteratively increasing $w$ from 0 to 1: anytime version of $WA^*$
            \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Modifications to Search Algorithms:}
\begin{summary}
    \begin{center}
        \begin{tabular}{l}
        \toprule
        \textbf{Modifications} \\
        \midrule
        \textbf{Depth-Limiting} \\
        \multicolumn{1}{p{\linewidth}}{
        \begin{itemize}
            \item Enforce a depth limit, $d_{\text{max}}$, to any search algorithm.
        \end{itemize}} \\
        \midrule
        \textbf{Iterative-Deepening} \\
        \multicolumn{1}{p{\linewidth}}{
        \begin{itemize}
            \item Iteratively increase the depth-limit to any search algorithm w/ depth-limiting.
        \end{itemize}} \\
        \midrule
        \textbf{Cost-Limiting} \\
        \multicolumn{1}{p{\linewidth}}{
        \begin{itemize}
            \item Enforce a cost limit of $c_\text{max}$ to any search algorithm.
        \end{itemize}} \\
        \midrule
        \textbf{Iterative Inflating} \\
        \multicolumn{1}{p{\linewidth}}{
        \begin{itemize}
            \item Iteratively increase the cost limit, $c_{\text{max}}$, to any search algorithm w/ cost-limiting.
        \end{itemize}} \\
        \midrule
        \textbf{Intra-Path Cycle Checking} \\
        \multicolumn{1}{p{\linewidth}}{
        \begin{itemize}
            \item Do not expand a path if it is cyclic.
        \end{itemize}} \\
        \midrule
        \textbf{Inter-Path Cycle Checking} \\
        \multicolumn{1}{p{\linewidth}}{
        \begin{itemize}
            \item Do not expand a path if its destination is that of an explored path. 
        \end{itemize}} \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{summary}
\newpage

\subsection{Setup}
\begin{definition} In a search problem, it is assumed that: 
    \begin{itemize}
        \item There is only one agent (us).
        \item For each state, $s \in S$, we have a discrete set of actions, $\mathcal{A}(s)$.
        \item The transition resulting from a move, $(s, a)$, is deterministic; the resulting state is $tr(s, a)$.
        \item $cst(s, a, tr(s, a))$ is our cost for the transition, $(s, a, tr(s, a))$.
        \item We want to realize a path that minimizes our cost.
    \end{itemize}
    
    A search problem may have no solutions, in which case, we define the solution as \texttt{NULL}.
\end{definition}

\subsection{Search Graphs}
\begin{definition}
    In a search graph (a graph representing a search problem):
    \begin{itemize}
        \item $S$ is defined by the vertices.
        \item $\mathcal{G}$ is a subset of the vertices.
        \item $s^{(0)}$ is some vertex.
        \item $tr(\cdot, \cdot)$ and $\mathcal{T}$ are defined by the edges.
        \item $cst(\cdot, \cdot, \cdot)$ is defined by the edge weights.
    \end{itemize}
\end{definition}

\subsection{Path Trees}
\begin{definition}
    A search algorithm explores a tree of possible paths. 
    \begin{itemize}
        \item In such a tree, each node represents the path from the root to itself.
        \begin{itemize}
            \item The node may also include other info (such as the path's origiin, cost, etc).
        \end{itemize}
    \end{itemize}
\end{definition}

\subsection{Search Algorithms}
\begin{definition}
    All search algorithms follow the template below:

\begin{lstlisting}
$\mathcal{O} \gets \{(\langle \rangle, 0)\}$ (*\hfill $\triangleright$ initialize a set of open nodes*) 
SEARCH($\mathcal{O}$)
\end{lstlisting}
\begin{itemize}
    \item $\langle \rangle$ is the empty path, and $0$ is the cost of the empty path.
\end{itemize}

\begin{lstlisting}
procedure SEARCH($\mathcal{O}$)
    if $\mathcal{O} = \emptyset$ then
        return NULL  (*\hfill $\triangleright$ the search algorithm failed to find a path to a goal*)
    $n \gets \textsc{Remove}(\mathcal{O})$ (*\hfill $\triangleright$ "explore" a node $n$*)
    if $\textsc{dst}(n) \in \mathcal{G}$ then
        return $n$ (*\hfill $\triangleright$ the search algorithm found a path to a goal*)
    for $n' \in \textsc{chl}(n)$ do
        $\mathcal{O} \gets \mathcal{O} \cup \{n'\}$ (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
    SEARCH($\mathcal{O}$)
\end{lstlisting}
\begin{itemize}
    \item Explore: Remove a node from the open set.
    \item Exapnd: Generate the children of the node.
    \item Export: Add the children to the open set.
\end{itemize}

\end{definition}

\begin{warning}
    The key difference is in the order that \textsc{Remove}($\cdot$) removes nodes.
\end{warning}

\subsection{Modifications to Search Algorithms}
\subsubsection{Depth-Limiting}
\begin{definition}
\begin{lstlisting}
procedure SEARCHDL($\mathcal{O}$, $d_{\text{max}}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL (*\hfill $\triangleright$ the search algorithm failed to find a path to a goal*)
    $n \leftarrow \text{REMOVE}(\mathcal{O})$ (*\hfill $\triangleright$ "explore" a node, $n$*)
    if dst($n$) $\in \mathcal{G}$ then
        return $n$ (*\hfill $\triangleright$ the search algorithm found a path to a goal*)
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if len($n'$) $\leq d_{\text{max}}$ then (*\hfill $\triangleright$ unless the child is too long*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCHDL($\mathcal{O}$, $d_{\text{max}}$)
\end{lstlisting}

\end{definition}

\subsubsection{Iterative Deepening}
\begin{definition}
\begin{lstlisting}
procedure SEARCHID():
    $n \leftarrow \text{NULL}$
    $d_{\text{max}} \leftarrow 0$
    (*$\triangleright$ while a solution has not been found, reset the open set, run the search algorithm, then increase the depth-limit*)
    while $n = \text{NULL}$ do
        $\mathcal{O} \leftarrow \{(\langle \rangle, 0)\}$
        $n \leftarrow \text{SEARCHDL}(\mathcal{O}, d_{\text{max}})$
        $d_{\text{max}} \leftarrow d_{\text{max}} + 1$
    return $n$
\end{lstlisting}
    
\end{definition}

\begin{warning}
    Increasing $d_{\text{max}}$ can be done in different ways.
\end{warning}

\subsubsection{Cost-Limiting}
\begin{definition}

\begin{lstlisting}
procedure SEARCHCL($\mathcal{O}$, $c_{\text{max}}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL (*\hfill $\triangleright$ the search algorithm failed to find a path to a goal*)
    $n \leftarrow \text{REMOVE}(\mathcal{O})$ (*\hfill $\triangleright$ "explore" a node, $n$*)
    if dst($n$) $\in \mathcal{G}$ then
        return $n$ (*\hfill $\triangleright$ the search algorithm found a path to a goal*)
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if cst($n'$) $\leq c_{\text{max}}$ then (*\hfill $\triangleright$ unless the child is too expensive*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCHCL($\mathcal{O}$, $c_{\text{max}}$)
\end{lstlisting}

\end{definition}
\newpage

\subsubsection{Iterative-Inflating}
\begin{definition}
\begin{lstlisting}
procedure SEARCHII():
    $n \leftarrow \text{NULL}$
    $c_{\text{max}} \leftarrow 0$
    (*$\triangleright$ while a solution has not been found, reset the open set, run the search algorithm, then increase the cost-limit*)
    while $n = \text{NULL}$ do
        $\mathcal{O} \leftarrow \{(\langle \rangle, 0)\}$
        $n \leftarrow \text{SEARCHCL}(\mathcal{O}, c_{\text{max}})$
        $c_{\text{max}} \leftarrow c_{\text{max}} + \epsilon$
    return $n$
\end{lstlisting}

\end{definition}

\begin{warning}
    Increasing $c_{\text{max}}$ can be done in different ways.
\end{warning}

\subsubsection{Intra-Path Cycle Checking}
\begin{definition}
\begin{lstlisting}
procedure SEARCH($\mathcal{O}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL
    $n \leftarrow \text{REMOVE}(\mathcal{O})$
    if dst($n$) $\in \mathcal{G}$ then
        return $n$
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if not CYCLIC($n'$) then (*\hfill $\triangleright$ unless the child is cyclic*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCH($\mathcal{O}$)
\end{lstlisting}
\begin{itemize}
    \item Optimately of an algorithm is preserved provided $\epsilon>0$.
\end{itemize}

\end{definition}

\subsubsection{Inter-Path Cycle Checking}
\begin{definition}
\begin{lstlisting}
procedure SEARCH($\mathcal{O}$, $\mathcal{C}$):
    if $\mathcal{O} = \emptyset$ then
        return NULL
    $n \leftarrow \text{REMOVE}(\mathcal{O})$
    $\mathcal{C} \leftarrow \mathcal{C} \cup \{n\}$ (*\hfill $\triangleright$ add $n$ to the closed set*)
    if dst($n$) $\in \mathcal{G}$ then
        return $n$
    for $n' \in \text{chl}(n)$ do (*\hfill $\triangleright$ "expand" $n$ and "export" its children*)
        if $n' \notin \mathcal{C}$ then (*\hfill $\triangleright$ unless the child's destination is closed*)
            $\mathcal{O} \leftarrow \mathcal{O} \cup \{n'\}$
    SEARCH($\mathcal{O}$, $\mathcal{C}$)
\end{lstlisting}

and then call the algorithm as follows:

\begin{lstlisting}[mathescape=true, escapeinside={(*}{*)}, numbers=left, frame=single]
$\mathcal{O} \leftarrow \{(\langle \rangle, 0)\}$
$\mathcal{C} \leftarrow \emptyset$ (*\hfill $\triangleright$ initialize a set of closed vertices*)
SEARCH($\mathcal{O}$, $\mathcal{C}$)
\end{lstlisting}

\end{definition}
\newpage

\subsection{Informed Search Algorithms}
\subsubsection{Estimated Cost}
\begin{definition}
    $\text{ecst}(\cdot)$: estimate of the total cost to a goal given a path, $p$, based on:
    \begin{itemize}
        \item $\text{cst}(p)$: Cost of path $p$
        \item $\text{hur} : S \to \mathbb{R}_+$: Estimate of the extra cost needed to get to a goal from $\text{dst}(p)$
        \begin{itemize}
            \item $\text{hur}(s)$ estimates the cost to get to $\mathcal{G}$ from $s$ and $\text{hur}(p)$ means $\text{hur}(\text{dst}(p))$.
        \end{itemize}
    \end{itemize}
\end{definition}

\subsubsection{Admissible}
\begin{definition}
    A heuristic, $\text{hur}(\cdot)$, is said to be \textbf{admissible} if

    \begin{equation*}
        \text{hur}(s) \leq \text{hur}^*(s)
    \end{equation*}

    for all $s \in \mathcal{S}$ and

    \begin{equation*}
        \text{hur}(s) = 0
    \end{equation*}

    for all $s \in \mathcal{G}$.
\end{definition}

\subsubsection{Consistent}
\begin{definition}
    A heuristic, $\text{hur}(\cdot)$, is said to be \textbf{consistent} if

    \begin{equation*}
        \underbrace{\text{hur}(s) - \text{hur}(\text{tr}(s,a))}_{\text{estimated cost of the transition }(s,a,\text{tr}(s,a))}
        \leq 
        \underbrace{\text{cst}(s,a,\text{tr}(s,a))}_{\text{true cost of the transition, }(s,a,\text{tr}(s,a))}
    \end{equation*}

    for all $s \in \mathcal{S}$, and $a \in \mathcal{A}(s)$, and

    \begin{equation*}
        \text{hur}(s) = 0
    \end{equation*}

    for all $s \in \mathcal{G}$.
\end{definition}

\subsubsection{Domination}
\begin{definition}
    If $\text{hur}_1$ and $\text{hur}_2$ are admissible, then:
    \begin{itemize}
        \item $\text{hur}_1$ \textbf{strongly dominates} $\text{hur}_2$ if for all $s \in \mathcal{S} \setminus \mathcal{G}$:
        \begin{equation*}
            \text{hur}_1(s) > \text{hur}_2(s)
        \end{equation*}

        \item $\text{hur}_1$ \textbf{weakly dominates} $\text{hur}_2$ if for all $s \in \mathcal{S}$:
        \begin{equation*}
            \text{hur}_1(s) \geq \text{hur}_2(s)
        \end{equation*}
        and for some $s \in \mathcal{S}$:
        \begin{equation*}
            \text{hur}_1(s) > \text{hur}_2(s)
        \end{equation*}
    \end{itemize}
\end{definition}

\subsubsection{Combining Heuristics}
\begin{definition}
    If $\{ \text{hur}_k(\cdot) \}_k$ are admissible (resp. consistent), then $\max_k \{\text{hur}_k\} (\cdot)$ is also admissible (resp. consistent).
\end{definition}

\begin{definition}
    If $\text{hur}_{\max} \equiv \max \{\text{hur}_1, \text{hur}_2\}$, then if $\text{hur}_k$ is consistent:
    \[
    \text{hur}_k(s) - \text{hur}_k(\text{tr}(s,a)) \leq \text{cst}(s,a,\text{tr}(s,a))
    \]
    \[
    \text{hur}_{\max} (s)= \text{hur}_{\max}(\text{tr}(s,a)) - \text{cst}^*(s,a,\text{tr}(s,a))
    \]
\end{definition}

\subsubsection{Anytime Search Algorithms}
\begin{definition}
    An \textbf{anytime algorithm} finds a solution quickly (even if it is sub-optimal), and then iteratively improves it (if time permits).
\end{definition}
\newpage

\subsection{Canonical Examples}
\begin{process} \textbf{How to setup a search problem?}
    \begin{enumerate}
        \item Givne a search graph, we need to define the following:
        \begin{itemize}
            \item $\mathcal{S}$: set of vertices
            \item $\mathcal{G}$: goal states (subset of $\mathcal{S}$)
            \item $s^{(0)}$: initial state
            \item $\mathcal{T}$: set of edges (defined by $\text{tr}(\cdot, \cdot)$)
            \begin{itemize}
                \item $\text{tr}(\cdot, \cdot)$: transition function
            \end{itemize}
            \item $\text{cst}(\cdot, \cdot, \cdot)$: cost function (defined by edge weights)
        \end{itemize}
    \end{enumerate}
\end{process}

\begin{example}
    \customFigure[0.5]{../Images/L2_0.png}{}
    \customFigure[0.5]{../Images/L2_1.png}{}
\end{example}
\newpage

\begin{example}
    \customFigure[0.5]{../Images/L2_9.png}{}
    \customFigure[0.5]{../Images/L2_10.png}{}
    \begin{itemize}
        \item $\mathcal{S} = \{0,\ldots,4 \}^2$
        \item $\mathcal{G} = \left\{ \begin{bmatrix}
            1 \\
            4
        \end{bmatrix} \right\}$
        \item $s^{(0)} = \begin{bmatrix}
            1 \\
            0
        \end{bmatrix}$
    \end{itemize}
\end{example}
\newpage


\begin{process} \textbf{How to setup a path tree?}
    \begin{enumerate}
        \item Start at $s^{(0)}$
        \item Choose a path until you reach a goal state.
        \item Repeat until you have found all paths (probably infinite).
    \end{enumerate}
\end{process}

\begin{example}
    \customFigure[0.5]{../Images/L2_2.png}{}
    \customFigure[0.5]{../Images/L2_3.png}{}
\end{example}

\newpage

\begin{process} \textbf{When to use each algorithm?}
    \begin{enumerate}
        \item Find properties needed for the problem and match them to the characteristics of the algorithm.
        \item Choose the algorithm that best matches the properties.
        \begin{itemize}
            \item \textbf{BFS:} 
            \item \textbf{DFS:} 
            \item \textbf{IDDFS:} 
            \item \textbf{CFS:}
            \item \textbf{A*:} 
        \end{itemize}
    \end{enumerate}
\end{process}

\begin{example}
    
\end{example}
\newpage

\begin{example}
    \customFigure[0.5]{../Images/LR_0.png}{}
\end{example}

\begin{process} \textbf{BFS}
    \begin{enumerate}
        \item Start at $s_0$ 
        \item Expand all neighboring nodes of the current node and add them to the open set (queue).
        \item Remove the current node from the open set and mark it as visited.
        \item Repeat steps 2 and 3 until the goal state is reached or the open set is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{BFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A\}$ \\
        $A$ & $\{B, C, D\}$ \\
        $AB$ & $\{C, D, E\}$ \\
        $ABC$ & $\{D, E\}$ \\
        $ABCD$ & $\{E\}$ \\
        $ABCDE$ & $\{\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{process} \textbf{DFS}
    \begin{enumerate}
        \item Start at $s_0$ (initial state).
        \item Push the initial node onto the stack.
        \item Pop a node from the stack and expand it.
        \item Push all unvisited children of the current node onto the stack.
        \item Repeat steps 3 and 4 until the goal state is reached or the stack is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{DFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A\}$ \\
        $A$ & $\{B,C,D\}$ \\
        $AD$ & $\{B,C,E\}$ \\
        $ADE$ & $\{C, B\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}


\begin{process} \textbf{IDDFS}
    \begin{enumerate}
        \item Start with a depth limit of 0.
        \item Perform Depth-First Search (DFS) up to the current depth limit.
        \item If the goal state is not reached and there are unexplored nodes, increment the depth limit and repeat step 2.
        \item Continue until the goal state is found or all nodes are explored.
    \end{enumerate}
\end{process}

\begin{example} \textbf{IDDFS}
    \begin{center}
        \begin{tabular}{lll}
        \toprule
        \textbf{Depth} & \textbf{Path} & \textbf{Open Set} \\
        \midrule
        0 & & $\{A\}$ \\
        0 & A & $\{\}$ \\
        \midrule
        1 & $A$ & $\{B, C, D\}$ \\
        1 & $AB$ & $\{C, D\}$ \\
        1 & $AC$ & $\{D\}$ \\
        1 & $AD$ & $\{\}$ \\
        \midrule
        2 & $AD$ & $\{E\}$ \\
        2 & $ADE$ & $\{\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{process} \textbf{CFS}
    \begin{enumerate}
        \item Start at $s_0$ (initial state).
        \item Initialize the open set (priority queue) with the initial state and its cost.
        \item Remove the node with the lowest cost from the open set.
        \item Expand the node and add all unvisited neighbors to the open set with their cumulative costs.
        \item Repeat steps 3 and 4 until the goal state is reached or the open set is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{CFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A \mid 0\}$ \\
        $A$ & $\{AB \mid 2, \; AC \mid 4, \; AD \mid 6\}$ \\
        $AB$ & $\{AC \mid 4, \; AD \mid 6, \; ABC \mid 3\}$ \\
        $ABC$ & $\{AC \mid 4, \; AD \mid 6, \; ABCE \mid 5, \; ABCD \mid 6\}$ \\
        $ABCE$ & $\{AC \mid 4, \; AD \mid 6, \; ABCD \mid 6\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{warning}
    \begin{itemize}
        \item How to perform shortcut? 
    \end{itemize}
\end{warning}

\begin{process} \textbf{HFS}
    \begin{enumerate}
        \item Start at $s_0$ (initial state).
        \item Initialize the open set with the initial state and its heuristic value.
        \item Remove the node with the lowest heuristic value from the open set.
        \item Expand the node and add all unvisited neighbors to the open set with their heuristic values.
        \item Repeat steps 3 and 4 until the goal state is reached or the open set is empty.
    \end{enumerate}
\end{process}

\begin{example} \textbf{HFS}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A \mid 3\}$ \\
        $A$ & $\{AB \mid 2, \; AC \mid 1, \; AD \mid 1\}$ \\
        $AC$ & $\{AB \mid 2, \; AD \mid 1, \; ACE \mid 0\}$ \\
        $ACE$ & $\{AB \mid 2, \; AD \mid 1\}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}


\begin{process} \textbf{A$^*$}
    \begin{enumerate}
        \item Start at $s_0$ 
        \item Choose path in open set that gives lowest $\text{esct}(p) = \text{cst}(p) + \text{hur}(p)$.
        \item Expand and export children onto open set.
        \item Repeat until goal state is reached.
    \end{enumerate}
\end{process}

\begin{example} \textbf{A$^*$}
    \begin{center}
        \begin{tabular}{ll}
        \toprule
        \textbf{Path} & \textbf{Open Set} \\
        \midrule
         & $\{A \mid 3 \}$ \\
        $A$ & $\{AB \mid 2 + 2, \; AC \mid 4 + 1, \; AD \mid 6 + 1\}$ \\
        $AB$ & $\{AC \mid 5, \; AD \mid 7, \; ABC \mid 3 + 1, \; \cancel{ABA} \quad \text{intra} \}$ \\
        $ABC$ & $\{AC \mid 5, AD \mid 7, \; ABCD \mid 6 + 1, \; ABCE \mid 5 + 0 \}$ \\
        $AC$ & $\{AD \mid 7, \; ABCD \mid 7, \; ABCE \mid 5, \; ACD \mid 7 + 1, \; ACE \mid 6 + 0 \}$ \\
        $ABCE$ & $\{AD \mid 7, \; ABCD \mid 7, \; ACD \mid 8, \; ACE \mid 6 \}$ \\
        \bottomrule
        \end{tabular}
    \end{center}
\end{example}

\begin{example} \textbf{IIA*}
    
\end{example}

\begin{example} \textbf{WA*}
    
\end{example}
\newpage

\begin{process} \textbf{How to Prove Consistent/Admissible Given a Search Graph?}
   
    \textbf{Admissible:}
    \begin{enumerate}
        \item Given $\text{hur}(s)$ and search graph with $\text{cst}(s,a,\text{tr}(s,a))$ or $\text{rwd}(s,a,\text{tr}(s,a))$. If consistent, then it is admissible.
        \item Check $\forall s \in \mathcal{G}$, $\text{hur}(s) = 0$. If not, then it is not admissible.
        \item For each $s \in \mathcal{S}$, calculate $\text{hur}^*(s)$ (i.e. actual cost of optimal soln.) using the search graph.
        \begin{enumerate}
            \item Start at $s$ and choose path that gives the lowest cost or highest reward to $s \in \mathcal{G}$. 
        \end{enumerate}
        \item Check if $\text{hur}(s) \leq \text{hur}^*(s) \; \forall s \in \mathcal{S}$. If not, then it is not admissible.
        \item Repeat $\forall s \in \mathcal{S}$. 
        \item If all are true, then it is admissible.
    \end{enumerate}
    \vspace{1em}

    \textbf{Consistent:}
    \begin{enumerate}
        \item Given $\text{hur}(s)$ and search graph with $\text{cst}(s,a,\text{tr}(s,a))$ or $\text{rwd}(s,a,\text{tr}(s,a))$. 
        \item Check $\forall s \in \mathcal{G}$, $\text{hur}(s) = 0$. If not, then it is not consistent.
        \item For each $s \in \mathcal{S}$, calculate $\text{hur}(s) - \text{hur}(\text{tr}(s, a))$.
        \begin{enumerate}
            \item check if it is $\leq \text{cst}(s,a,\text{tr}(s,a))$ or $\geq \text{rwd}(s,a,\text{tr}(s,a))$. If not, then it is not consistent.
            \item Repeat $\forall a \in \mathcal{A}(s)$
        \end{enumerate}
        \item Repeat $\forall s \in \mathcal{S}$.
        \item If all are true, then it is consistent.
    \end{enumerate}
\end{process}

\begin{warning}
    Be careful of bidirectional edges bc for consistency you need compute the cost of the heuristic edge in both directions.
\end{warning}

\begin{example}
    \customFigure[0.5]{../Images/L2_8.png}{Jungle ($s^{(0)}$), Desert, Swamp, Mountain, Plains (Goal)}

    \textbf{Admissible:}
    \begin{enumerate}
        \item \textbf{$s=$Plains:} $\text{hur}(\text{Plains}) = 0$ 
        \item \textbf{$s=$Jungle:} $\text{hur}(\text{Jungle}) = 3 \leq \text{hur}^*(\text{Jungle}) = 2 + 1 + 2 = 5$
        \item \textbf{$s=$Desert:} $\text{hur}(\text{Desert}) = 2 \leq \text{hur}^*(\text{Desert}) = 1 + 2$
        \item \textbf{$s=$Swamp:} $\text{hur}(\text{Swamp}) = 1 \leq \text{hur}^*(\text{Swamp}) = 2$
        \item \textbf{$s=$Mountain:} $\text{hur}(\text{Mountain}) = 1 \leq \text{hur}^*(\text{Mountain}) = 1$
        \item Therefore, it is admissible.
    \end{enumerate}
    \vspace{1em}

    \textbf{Consistent:}
    \begin{enumerate}
        \item \textbf{$s=$Plains:} $\text{hur}(\text{Plains}) = 0$
        \item \textbf{$s=$Jungle:}
        \begin{enumerate}
            \item $\text{hur}(\text{Jungle}) - \text{hur}(\text{Desert}) = 3 - 2 = 1 \leq \text{cst}(\text{Jungle}, \cdot, \text{Desert}) = 2$
            \item $\text{hur}(\text{Jungle}) - \text{hur}(\text{Swamp}) = 3 - 1 = 2 \leq \text{cst}(\text{Jungle}, \cdot, \text{Swamp}) = 4$
            \item $\text{hur}(\text{Jungle}) - \text{hur}(\text{Mountain}) = 3 - 1 = 2 \leq \text{cst}(\text{Jungle}, \cdot, \text{Mountain}) = 6$
        \end{enumerate}
        \item \textbf{$s=$Desert:} 
        \begin{enumerate}
            \item $\text{hur}(\text{Desert}) - \text{hur}(\text{Jungle}) = 2 - 3 = -1 \leq \text{cst}(\text{Desert}, \cdot, \text{Jungle}) = 2$
            \item $\text{hur}(\text{Desert}) - \text{hur}(\text{Swamp}) = 2 - 1 = 1 \leq \text{cst}(\text{Desert}, \cdot, \text{Swamp}) = 1$
        \end{enumerate}
        \item \textbf{$s=$Swamp:}
        \begin{enumerate}
             \item $\text{hur}(\text{Swamp}) - \text{hur}(\text{Mountain}) = 1 - 1 = 0 \leq \text{cst}(\text{Swamp}, \cdot, \text{Mountain}) = 3$
            \item $\text{hur}(\text{Swamp}) - \text{hur}(\text{Plains}) = 1 - 0 = 1 \leq \text{cst}(\text{Swamp}, \cdot, \text{Plains}) = 2$
        \end{enumerate}
        \item \textbf{$s=$Mountain:} 
        \begin{enumerate}
            \item $\text{hur}(\text{Mountain}) - \text{hur}(\text{Jungle}) = 1 - 3 = -2 \leq \text{cst}(\text{Mountain}, \cdot, \text{Desert}) = 6$
            \item $\text{hur}(\text{Mountain}) - \text{hur}(\text{Plains}) = 1 - 0 = 1 \leq \text{cst}(\text{Mountain}, \cdot, \text{Plains}) = 1$
        \end{enumerate}
        \item Therefore, it is consistent.
    \end{enumerate}
\end{example}
\newpage

\begin{process} \textbf{How to Design Heuristic via Problem Relaxation?}
    \begin{enumerate}
        \item Make an assumption to simplify the problem as a relaxed problem. 
        \item Find the cost of the optimal solution of the relaxed problem, $\text{cst}_{\text{rel}}(s)$.
        \item HOW TO FIND THE COST OF THE OPTIMAL SOLUTION?
    \end{enumerate}
\end{process}

\begin{example}
    \customFigure[0.5]{../Images/L2_11.png}{}
\end{example}








